{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qutrit Machine Learning Optimizaiton "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Bora Basyildiz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qutrit Fidelity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_Qutrit(J,B,M,input_gate,t,N_iter):\n",
    "    #!/usr/bin/env python3\n",
    "    # -*- coding: utf-8 -*-\n",
    "    \"\"\"\n",
    "    Created on Mon Aug 16 4:33 2021\n",
    "\n",
    "    @author: Bora & Alex\n",
    "    \"\"\"\n",
    "    #imports\n",
    "\n",
    "    #Pauli Matricies \n",
    "    l1 = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 0]]) \n",
    "    l2 = np.array([[0,-1j, 0],[1j,0, 0], [0, 0, 0]]) \n",
    "    l3 = np.array([[1, 0, 0], [0, -1, 0], [0, 0, 0]]) \n",
    "    l4 = np.array([[0,0,1],[0,0,0],[1,0,0]])\n",
    "    l5 = np.array([[0,0,-1j],[0,0,0],[1j,0,0]])\n",
    "    l6 = np.array([[0,0,0],[0,0,1],[0,1,0]]) #essentially X for 1->2 transition\n",
    "    l7 = np.array([[0,0,0],[0,0,-1j],[0,1j,0]]) #essentially Y for 1->2 transition\n",
    "    l8 = 1/np.sqrt(3) * np.array([[1,0,0],[0,1,0],[0,0,-2]])\n",
    "    id = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 1]])\n",
    "\n",
    "    sx = np.array([[0,1,0],[1,0,0],[0,0,1]])\n",
    "    sy = np.array([[0,-1j,0],[1j,0,0],[0,0,1]])\n",
    "    sx2 = np.array([[1,0,0],[0,0,1],[0,1,0]])\n",
    "    sy2 = np.array([[1,0,0],[0,0,-1j],[0,1j,0]])\n",
    "    sx02 = np.array([[0,0,1],[0,1,0],[1,0,0]])\n",
    "    sy02 = np.array([[0,0,-1j],[0,1,0],[1j,0,0]])\n",
    "    sz = np.array([[1,0,0],[0,-1,0],[0,0,1]])\n",
    "    \n",
    "    #Function definitions \n",
    "    def zero_mat(N):#Generates matrix of zeros\n",
    "        zero_gate = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        init = zero_gate\n",
    "        if N < 2:\n",
    "            return 1\n",
    "        for i in range(0,N - 1):\n",
    "            zero_gate = torch.tensor(np.kron(zero_gate,init),dtype=torch.cdouble)\n",
    "        return zero_gate\n",
    "    def sum_pauli(coef, gate):#Sums Pauli gates with coefficients \n",
    "        N = len(coef)#number of qubits\n",
    "        total_pauli = zero_mat(N)\n",
    "        #Summing all Z gates\n",
    "        for i in range(0,N):\n",
    "            pauli_temp = 1\n",
    "            for j in range(0,i):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            pauli_temp = torch.tensor(np.kron(pauli_temp,gate))\n",
    "            for j in range(i+1,N):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            total_pauli = total_pauli + coef[i]*pauli_temp\n",
    "        #return torch.tensor(total_pauli,dtype=torch.cdouble)\n",
    "        return total_pauli\n",
    "\n",
    "    #variable initializations\n",
    "    N = len(B)\n",
    "    torch.manual_seed(1)\n",
    "    dt = torch.cdouble # datatype and precision\n",
    "    infidelity_list=torch.zeros([N_iter,1])\n",
    "\n",
    "    #J coefficients gathering (only if J is in N x N matrix, otherwise set J_coef=J) <- essentially flattens the array\n",
    "    J_coef = []\n",
    "    for i in range(0,len(J) - 1):\n",
    "        for j in range(0,len(J) - i - 1):\n",
    "            J_coef.append(J[i,j].item())\n",
    "\n",
    "    #H0 generation\n",
    "    permuts = [1,1]\n",
    "    for i in range(2,N):\n",
    "        permuts.append(0)\n",
    "    permuts = list(set(permutations(permuts,N)))\n",
    "    permuts.sort()\n",
    "    permuts.reverse()#All permutations of ZZ coupling stored as bit arrays\n",
    "    H0 = zero_mat(N)\n",
    "    ##Changed gates ZZ -> XX\n",
    "    for i,u in enumerate(permuts):#summing ZZ permutations and J constants\n",
    "        XX_temp = 1\n",
    "        for p in u:\n",
    "            if p==1:\n",
    "                XX_temp = torch.tensor(np.kron(XX_temp,l1))\n",
    "            else:\n",
    "                XX_temp = torch.tensor(np.kron(XX_temp,id))\n",
    "        H0 = H0 + J_coef[i]*XX_temp\n",
    "    #H0 = H0 + sum_pauli(B,sz)\n",
    "\n",
    "    #These are the coefficients we are optimizing\n",
    "    R = torch.rand([M,4*N], dtype=torch.double) *2*np.pi # Random initialization (between 0 and 2pi)\n",
    "    R.requires_grad = True # set flag so we can backpropagate\n",
    "\n",
    "    #Optimizer settings(can be changed & opttimized)\n",
    "    lr=0.3#learning rate\n",
    "\n",
    "    opt = 'SGD'  # Choose optimizer - ADAM, SGD (typical). ADAMW, ADAMax, Adadelta,  \n",
    "                        # Adagrad, Rprop, RMSprop, ASGD, also valid options.     \n",
    "    sched = 'Plateau'  # Choose learning rate scheduler - Plateau, Exponential (typical), Step\n",
    "    \n",
    "    if opt=='ADAM': optimizer = torch.optim.Adam([R], lr = lr, weight_decay=1e-6)\n",
    "    elif opt=='ADAMW': optimizer = torch.optim.AdamW([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='ADAMax': optimizer = torch.optim.Adamax([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='RMSprop': optimizer = torch.optim.RMSprop([R], lr = lr, momentum=0.2)\n",
    "    elif opt=='Rprop': optimizer = torch.optim.Rprop([R], lr = lr)\n",
    "    elif opt=='Adadelta': optimizer = torch.optim.Adadelta([R], lr = lr) \n",
    "    elif opt=='Adagrad': optimizer = torch.optim.Adagrad([R], lr = lr)\n",
    "    elif opt=='SGD': optimizer = torch.optim.SGD([R], lr = lr, momentum=0.99, nesterov=True)\n",
    "    elif opt=='ASGD': optimizer = torch.optim.ASGD([R], lr = lr)\n",
    "    else: optimizer=None; opt='None'\n",
    "        \n",
    "    if sched=='Step': scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=N_iter/10, gamma=0.9)\n",
    "    elif sched=='Exponential': scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    elif sched=='Plateau': scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=0.03, factor=0.3 , patience= 20 ); loss_in=True; \n",
    "    else: scheduler=None; sched='None'\n",
    "\n",
    "    for n in range(0,N_iter):\n",
    "        #Creating Drive Hamilontian\n",
    "        U_Exp = 1\n",
    "        for i in range(0,N):\n",
    "            U_Exp = torch.tensor(np.kron(U_Exp,id),dtype=dt)#initializing unitary\n",
    "        for m in range(0,M):#Product of pulses\n",
    "            pulse_coef = R[m]\n",
    "            #H1 = sum_pauli(pulse_coef[:N],l1) + sum_pauli(pulse_coef[N:2*N],l2) + sum_pauli(pulse_coef[2*N:3*N],l4) + sum_pauli(pulse_coef[3*N:4*N],l5) + sum_pauli(pulse_coef[4*N:5*N],l6) + sum_pauli(pulse_coef[5*N:],l7) \n",
    "            H1 = sum_pauli(pulse_coef[:N],l1) + sum_pauli(pulse_coef[N:2*N],l2) + sum_pauli(pulse_coef[2*N:3*N],l4) \n",
    "            #H1 = sum_pauli(pulse_coef[:N],l1) + sum_pauli(pulse_coef[N:2*N],l2) \n",
    "            U_Exp = torch.matmul(torch.matrix_exp(-1j*(H0+H1)*t/M),U_Exp)\n",
    "        \n",
    "        #Orthonormal Matrix Generation \n",
    "        def Matrix_Basis_Gen(d):\n",
    "            X = np.zeros([d,d])\n",
    "            for i in range(d):\n",
    "                X[(i+1) % d,i] = 1\n",
    "            Z = np.zeros([d,d],dtype=np.complex_)\n",
    "            for i in range(d):\n",
    "                Z[i,i] = np.exp((2*np.pi * 1j * i)/d)\n",
    "            Basis = []\n",
    "            for i in range(d):\n",
    "                for j in range(d):\n",
    "                    Basis.append(torch.tensor(np.matmul(np.linalg.matrix_power(X,i),np.linalg.matrix_power(Z,j)),dtype=torch.cdouble))\n",
    "            return Basis\n",
    "\n",
    "        #Fidelity calulcation given by Nielsen Paper\n",
    "        fidelity = 0\n",
    "        d = 3**N\n",
    "        \n",
    "        for U in Matrix_Basis_Gen(d):\n",
    "            ideal_U = torch.matmul(torch.matmul(input_gate,U.conj().T),(input_gate.conj().T))\n",
    "            target_U = torch.matmul(torch.matmul(U_Exp,U),(U_Exp.conj().T)) # This is Eps(U) = pulse_gate * pauli * pulse_gate^H\n",
    "            tr = torch.trace(torch.matmul(ideal_U,target_U))\n",
    "            fidelity = fidelity + tr \n",
    "        fidelity = abs(fidelity + d**2)/(d**2 *(d+1))    \n",
    "        infidelity = 1 - fidelity\n",
    "        infidelity_list[n] = infidelity.detach()\n",
    "        infidelity.backward()\n",
    "\n",
    "        #Printing statement\n",
    "        if (n+1)%50==0: \n",
    "            print('Itertation ', str(n+1), ' out of ', str(N_iter), 'complete. Avg Infidelity: ', str(infidelity.item()))\n",
    "\n",
    "        #optimizer \n",
    "        if optimizer is not None and scheduler is None:  # Update R\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        elif optimizer is not None and scheduler is not None:\n",
    "            optimizer.step()\n",
    "            if loss_in: \n",
    "                scheduler.step(infidelity)\n",
    "            else: \n",
    "                scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            R.data.sub_(lr*R.grad.data) # using data avoids overwriting tensor object\n",
    "            R.grad.data.zero_()           # and it's respective grad info\n",
    "    \n",
    "    #print('The infidelity of the generated gate is: ' + str(infidelity_list.min().item()))\n",
    "    return R\n",
    "    #return infidelity_list.min().item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qutrit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itertation  50  out of  500 complete. Avg Infidelity:  0.6668540853001168\n",
      "Itertation  100  out of  500 complete. Avg Infidelity:  0.12188696872874771\n",
      "Itertation  150  out of  500 complete. Avg Infidelity:  0.06620903413448509\n",
      "Itertation  200  out of  500 complete. Avg Infidelity:  0.03352852279408569\n",
      "Itertation  250  out of  500 complete. Avg Infidelity:  0.021078520458632788\n",
      "Itertation  300  out of  500 complete. Avg Infidelity:  0.015019297451007163\n",
      "Itertation  350  out of  500 complete. Avg Infidelity:  0.01124172237670995\n",
      "Itertation  400  out of  500 complete. Avg Infidelity:  0.007746816145300706\n",
      "Itertation  450  out of  500 complete. Avg Infidelity:  0.0056685238385622005\n",
      "Itertation  500  out of  500 complete. Avg Infidelity:  0.0045648347782324405\n"
     ]
    }
   ],
   "source": [
    "CNOT_qutrit = torch.tensor([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,1,0,0,0],\n",
    "[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,1]],dtype=torch.cdouble)\n",
    "Identity = torch.tensor([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[0,0,0,0,0,1,0,0,0],\n",
    "[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,1]],dtype=torch.cdouble)\n",
    "J = torch.tensor([[1,1],[1,1]])\n",
    "pulse_frequencies = fidelity_Qutrit(J,[1,1],16,Identity,np.pi,500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qutrit Matrix Basis Generation Explanation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a matrix basis that is orthonormal AND unitary. While the Gell-Mann matrices are orthonormal, they are not unitary. Now we will generate these matrices through the method outlined by the Nielsen paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrix_Basis_Gen(d):\n",
    "            X = np.zeros([d,d])\n",
    "            for i in range(d):\n",
    "                X[(i+1) % d,i] = 1\n",
    "            Z = np.zeros([d,d],dtype=np.complex_)\n",
    "            for i in range(d):\n",
    "                Z[i,i] = np.exp((2*np.pi * 1j * i)/d)\n",
    "            Basis = []\n",
    "            for i in range(d):\n",
    "                for j in range(d):\n",
    "                    Basis.append(torch.tensor(np.matmul(np.linalg.matrix_power(X,i),np.linalg.matrix_power(Z,j)),dtype=torch.cdouble))\n",
    "            return Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 1.+0.j]], dtype=torch.complex128),\n",
       " tensor([[ 1.+0.0000e+00j,  0.+0.0000e+00j],\n",
       "         [ 0.+0.0000e+00j, -1.+1.2246e-16j]], dtype=torch.complex128),\n",
       " tensor([[0.+0.j, 1.+0.j],\n",
       "         [1.+0.j, 0.+0.j]], dtype=torch.complex128),\n",
       " tensor([[ 0.+0.0000e+00j, -1.+1.2246e-16j],\n",
       "         [ 1.+0.0000e+00j,  0.+0.0000e+00j]], dtype=torch.complex128)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix_Basis_Gen(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efa8cc2a4d6f65357a972a944fbd3e02e547e4ca88e36cc716fc5e5cc822571e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
