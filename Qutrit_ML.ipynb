{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qutrit Machine Learning Optimizaiton "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Bora Basyildiz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qutrit Fidelity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_Qutrit(J,B,M,input_gate,t,N_iter):\n",
    "    #!/usr/bin/env python3\n",
    "    # -*- coding: utf-8 -*-\n",
    "    \"\"\"\n",
    "    Created on Mon Aug 16 4:33 2021\n",
    "\n",
    "    @author: Bora & Alex\n",
    "\n",
    "    This function extends the architecture from \n",
    "    \"\"\"\n",
    "    #imports\n",
    "\n",
    "    #Gell-Mann Matricies \n",
    "    l1 = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 0]]) #~X for 0->1 transition\n",
    "    l2 = np.array([[0,-1j, 0],[1j,0, 0], [0, 0, 0]]) #~Y for 0->1 transition\n",
    "    l3 = np.array([[1, 0, 0], [0, -1, 0], [0, 0, 0]]) #~Z for qubit regime\n",
    "    l4 = np.array([[0,0,1],[0,0,0],[1,0,0]]) #~X for 0->2 transition\n",
    "    l5 = np.array([[0,0,-1j],[0,0,0],[1j,0,0]]) #~Y for 0->2 transition\n",
    "    l6 = np.array([[0,0,0],[0,0,1],[0,1,0]]) #~X for 1->2 transition\n",
    "    l7 = np.array([[0,0,0],[0,0,-1j],[0,1j,0]]) #~Y for 1->2 transition\n",
    "    l8 = 1/np.sqrt(3) * np.array([[1,0,0],[0,1,0],[0,0,-2]]) #Some sort of phase gate\n",
    "    id = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 1]]) #Aye, if you don't know the identity at this point, its maybe time for another career.\n",
    "\n",
    "    # Annhilation and Creation Operators (used for PRA Hamiltonian)\n",
    "    annhilate = np.array([[0,1,0],[0,0,np.sqrt(2)],[0,0,0]])\n",
    "    create = annhilate.T\n",
    "    \n",
    "    #Function definitions \n",
    "    def zero_mat(N):#Generates matrix of zeros\n",
    "        zero_gate = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        init = zero_gate\n",
    "        if N < 2:\n",
    "            return 1\n",
    "        for i in range(0,N - 1):\n",
    "            zero_gate = torch.tensor(np.kron(zero_gate,init),dtype=torch.cdouble)\n",
    "        return zero_gate\n",
    "    def sum_pauli(coef, gate):#Sums Pauli gates with coefficients \n",
    "        N = len(coef)#number of qubits\n",
    "        total_pauli = zero_mat(N)\n",
    "        #Summing all Z gates\n",
    "        for i in range(0,N):\n",
    "            pauli_temp = 1\n",
    "            for j in range(0,i):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            pauli_temp = torch.tensor(np.kron(pauli_temp,gate))\n",
    "            for j in range(i+1,N):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            total_pauli = total_pauli + coef[i]*pauli_temp\n",
    "        #return torch.tensor(total_pauli,dtype=torch.cdouble)\n",
    "        return total_pauli\n",
    "\n",
    "    #variable initializations\n",
    "    N = len(B)\n",
    "    torch.manual_seed(random.randint(0,1000))\n",
    "    dt = torch.cdouble # datatype and precision\n",
    "    infidelity_list=torch.zeros([N_iter,1])\n",
    "\n",
    "    #J coefficients gathering (only if J is in N x N matrix, otherwise set J_coef=J) <- essentially flattens the array\n",
    "    J_coef = []\n",
    "    for i in range(0,len(J) - 1):\n",
    "        for j in range(0,len(J) - i - 1):\n",
    "            J_coef.append(J[i,j].item())\n",
    "\n",
    "    #H0 generation\n",
    "    permuts = [1,1]\n",
    "    for i in range(2,N):\n",
    "        permuts.append(0)\n",
    "    permuts = list(set(permutations(permuts,N)))\n",
    "    permuts.sort()\n",
    "    permuts.reverse()#All permutations of ZZ coupling stored as bit arrays\n",
    "    H0 = zero_mat(N)\n",
    "    ##Changed gates ZZ -> XX\n",
    "    for i,u in enumerate(permuts):\n",
    "        H0_temp = 1\n",
    "        for p in u:\n",
    "            if p==1:\n",
    "                H0_temp = torch.tensor(np.kron(H0_temp,(annhilate + create)))\n",
    "            else:\n",
    "                H0_temp = torch.tensor(np.kron(H0_temp,id))\n",
    "        H0 = H0 + J_coef[i]*H0_temp\n",
    "\n",
    "    #Orthonormal Matrix Generation \n",
    "    def Matrix_Basis_Gen(d):\n",
    "        X = np.zeros([d,d])\n",
    "        for i in range(d):\n",
    "            X[(i+1) % d,i] = 1\n",
    "        Z = np.zeros([d,d],dtype=np.complex_)\n",
    "        for i in range(d):\n",
    "            Z[i,i] = np.exp((2*np.pi * 1j * i)/d)\n",
    "        Basis = []\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                Basis.append(torch.tensor(np.matmul(np.linalg.matrix_power(X,i),np.linalg.matrix_power(Z,j)),dtype=torch.cdouble))\n",
    "        return Basis\n",
    "\n",
    "    #These are the coefficients we are optimizing\n",
    "    R = torch.rand([M,4*N], dtype=torch.double) *2*np.pi # Random initialization (between 0 and 2pi)\n",
    "    R.requires_grad = True # set flag so we can backpropagate\n",
    "\n",
    "    #Optimizer settings(can be changed & opttimized)\n",
    "    lr=0.3#learning rate\n",
    "\n",
    "    opt = 'SGD'  # Choose optimizer - ADAM, SGD (typical). ADAMW, ADAMax, Adadelta,  \n",
    "                        # Adagrad, Rprop, RMSprop, ASGD, also valid options.     \n",
    "    sched = 'Plateau'  # Choose learning rate scheduler - Plateau, Exponential (typical), Step\n",
    "    \n",
    "    if opt=='ADAM': optimizer = torch.optim.Adam([R], lr = lr, weight_decay=1e-6)\n",
    "    elif opt=='ADAMW': optimizer = torch.optim.AdamW([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='ADAMax': optimizer = torch.optim.Adamax([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='RMSprop': optimizer = torch.optim.RMSprop([R], lr = lr, momentum=0.2)\n",
    "    elif opt=='Rprop': optimizer = torch.optim.Rprop([R], lr = lr)\n",
    "    elif opt=='Adadelta': optimizer = torch.optim.Adadelta([R], lr = lr) \n",
    "    elif opt=='Adagrad': optimizer = torch.optim.Adagrad([R], lr = lr)\n",
    "    elif opt=='SGD': optimizer = torch.optim.SGD([R], lr = lr, momentum=0.99, nesterov=True)\n",
    "    elif opt=='ASGD': optimizer = torch.optim.ASGD([R], lr = lr)\n",
    "    else: optimizer=None; opt='None'\n",
    "        \n",
    "    if sched=='Step': scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=N_iter/10, gamma=0.9)\n",
    "    elif sched=='Exponential': scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    elif sched=='Plateau': scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=0.03, factor=0.3 , patience= 20 ); loss_in=True; \n",
    "    else: scheduler=None; sched='None'\n",
    "\n",
    "    for n in range(0,N_iter):\n",
    "        #Creating Drive Hamilontian\n",
    "        U_Exp = 1\n",
    "        for i in range(0,N):\n",
    "            U_Exp = torch.tensor(np.kron(U_Exp,id),dtype=dt)#initializing unitary\n",
    "        for m in range(0,M):#Product of pulses\n",
    "            pulse_coef = R[m]\n",
    "            H1 = sum_pauli(pulse_coef[:N],l1) + sum_pauli(pulse_coef[N:2*N],l2) + sum_pauli(pulse_coef[2*N:3*N],l6) + sum_pauli(pulse_coef[3*N:4*N],l7) \n",
    "            U_Exp = torch.matmul(torch.matrix_exp(-1j*(H0+H1)*t/M),U_Exp)\n",
    "\n",
    "        #Fidelity calulcation given by Nielsen Paper\n",
    "        fidelity = 0\n",
    "        d = 3**N\n",
    "        \n",
    "        for U in Matrix_Basis_Gen(d):\n",
    "            ideal_U = torch.matmul(torch.matmul(input_gate,U.conj().T),(input_gate.conj().T))\n",
    "            target_U = torch.matmul(torch.matmul(U_Exp,U),(U_Exp.conj().T)) # This is Eps(U) = pulse_gate * pauli * pulse_gate^H\n",
    "            tr = torch.trace(torch.matmul(ideal_U,target_U))\n",
    "            fidelity = fidelity + tr \n",
    "        fidelity = abs(fidelity + d**2)/(d**2 *(d+1))    \n",
    "        infidelity = 1 - fidelity\n",
    "        infidelity_list[n] = infidelity.detach()\n",
    "        infidelity.backward()\n",
    "\n",
    "        #Printing statement\n",
    "        if (n+1)%1000==0: \n",
    "            print('Itertation ', str(n+1), ' out of ', str(N_iter), 'complete. Avg Infidelity: ', str(infidelity.item()))\n",
    "\n",
    "        #optimizer \n",
    "        if optimizer is not None and scheduler is None:  # Update R\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        elif optimizer is not None and scheduler is not None:\n",
    "            optimizer.step()\n",
    "            if loss_in: \n",
    "                scheduler.step(infidelity)\n",
    "            else: \n",
    "                scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            R.data.sub_(lr*R.grad.data) # using data avoids overwriting tensor object\n",
    "            R.grad.data.zero_()           # and it's respective grad info\n",
    "    \n",
    "    #print('The infidelity of the generated gate is: ' + str(infidelity_list.min().item()))\n",
    "    #return R\n",
    "    return infidelity_list.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_subQutrit(J,B,M,input_gate,t,N_iter,pulse_file):\n",
    "    #!/usr/bin/env python3\n",
    "    # -*- coding: utf-8 -*-\n",
    "    \"\"\"\n",
    "    Created on Mon Aug 16 4:33 2021\n",
    "\n",
    "    @author: Bora & Alex\n",
    "\n",
    "\n",
    "    This function is essentially the qubit optimization done by Alex & I in Joel's experiment. But now we have drives from the |0> -> |1> and |1> -> |2>. \n",
    "    We still are generating 2-qubit gates, but the inclusion of qutrit drives minimizes the generation time. See PRA paper promising initial results.  \n",
    "    \"\"\"\n",
    "    #imports\n",
    "\n",
    "    #Experimental Parameters\n",
    "    g = 1\n",
    "    maxFreq = 5*g\n",
    "\n",
    "    #Pauli Matricies in Qutrit space\n",
    "    sx = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 0]]) \n",
    "    sy = np.array([[0,-1j, 0],[1j,0, 0], [0, 0, 0]]) \n",
    "    sz = np.array([[1, 0, 0], [0, -1, 0], [0, 0, 0]]) \n",
    "    id = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 0]]) # note that the identity does not have a value in the |2> state. This is because we want our gates only to operate in the qubit space. \n",
    "\n",
    "    # Annhilation and Creation Operators (for PRA Hamiltonian)\n",
    "    annhilate = np.array([[0,1,0],[0,0,np.sqrt(2)],[0,0,0]])\n",
    "    create = annhilate.T\n",
    "\n",
    "    # Drives for Qutrit transitions (Gell-Mann Matrices)\n",
    "    sxx = np.array([[0,0,0],[0,0,1],[0,1,0]]) #~X for 1->2 transition\n",
    "    syy = np.array([[0,0,0],[0,0,-1j],[0,1j,0]]) #~Y for 1->2 transition\n",
    "    \n",
    "    #Function definitions \n",
    "    def zero_mat(N):#Generates matrix of zeros\n",
    "        zero_gate = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        init = zero_gate\n",
    "        if N < 2:\n",
    "            return 1\n",
    "        for i in range(0,N - 1):\n",
    "            zero_gate = torch.tensor(np.kron(zero_gate,init))\n",
    "        return zero_gate\n",
    "    def sum_pauli(coef, gate):#Sums Pauli gates with coefficients \n",
    "        N = len(coef)#number of qubits\n",
    "        total_pauli = zero_mat(N)\n",
    "        #Summing all Z gates\n",
    "        for i in range(0,N):\n",
    "            pauli_temp = 1\n",
    "            for j in range(0,i):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            pauli_temp = torch.tensor(np.kron(pauli_temp,gate))\n",
    "            for j in range(i+1,N):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            #total_pauli = total_pauli + maxFreq*torch.cos(coef[i])*pauli_temp\n",
    "            total_pauli = total_pauli + coef[i]*pauli_temp\n",
    "        return total_pauli\n",
    "\n",
    "    #variable initializations\n",
    "    N = len(B)\n",
    "    #torch.manual_seed(9)\n",
    "    torch.manual_seed(random.randint(0,1000))\n",
    "    dt = torch.cdouble # datatype and precision\n",
    "    infidelity_list=torch.zeros([N_iter,1])\n",
    "\n",
    "    #J coefficients gathering (only if J is in N x N matrix, otherwise set J_coef=J) <- essentially flattens the array\n",
    "    J_coef = []\n",
    "    for i in range(0,len(J) - 1):\n",
    "        for j in range(0,len(J) - i - 1):\n",
    "            J_coef.append(J[i,j].item())\n",
    "\n",
    "    #H0 generation\n",
    "    permuts = [1,1]\n",
    "    for i in range(2,N):\n",
    "        permuts.append(0)\n",
    "    permuts = list(set(permutations(permuts,N)))\n",
    "    permuts.sort()\n",
    "    permuts.reverse()#All permutations of coupling stored as bit arrays\n",
    "    H0 = torch.tensor(zero_mat(N),dtype=torch.cdouble)\n",
    "    eigen_energies = [0, 5.440, 10.681, 4.994, 10.433, 15.666, 9.832, 15.270, 20.506] # experimentally given by Ray's Group\n",
    "    #Diagonal energies of Hamiltonian\n",
    "    for i,e in enumerate(eigen_energies):\n",
    "        H0[i,i] = float(e)\n",
    "\n",
    "    #Coupling terms in Hamiltonian (g1(|01><10| + h.c.) + g2(|12><21| + h.c.)\n",
    "    g1 = g #What are the values fo g1 are g2? \n",
    "    g2 = g1\n",
    "    one_transition = np.outer(np.array([0,1,0,0,0,0,0,0,0]),np.array([0,0,0,1,0,0,0,0,0])) \n",
    "    two_transition = np.outer(np.array([0,0,0,0,1,0,0,0,0]),np.array([0,0,0,0,0,0,0,1,0])) \n",
    "    H0 = H0 + g1*(torch.tensor(one_transition + np.conjugate(one_transition).T)) + g2*(torch.tensor(two_transition + np.conjugate(two_transition).T))\n",
    "    #for i,u in enumerate(permuts): # This is the Hamiltonian from the Ashabb paper \n",
    "    #    Coupling_temp = 1\n",
    "    #    for p in u:\n",
    "    #        if p==1:\n",
    "    #            Coupling_temp = torch.tensor(np.kron(Coupling_temp,annhilate + create))\n",
    "    #        else:\n",
    "    #            Coupling_temp = torch.tensor(np.kron(Coupling_temp,id))\n",
    "    #    H0 = H0 + J_coef[i]*Coupling_temp\n",
    "\n",
    "    #Unitary group generation\n",
    "    SU = []\n",
    "    pauli_int = [1,2,3,4]\n",
    "    perms = list(product(pauli_int,repeat=N))#all permutations of paulis\n",
    "    for p in perms:#mapping integers to pauli \n",
    "        unitary = 1\n",
    "        for pauli in p:\n",
    "            if pauli == 1:\n",
    "                unitary = torch.tensor(np.kron(unitary,sx),dtype=torch.cdouble)\n",
    "            elif pauli == 2:\n",
    "                unitary = torch.tensor(np.kron(unitary,sy),dtype=torch.cdouble)\n",
    "            elif pauli == 3:\n",
    "                unitary = torch.tensor(np.kron(unitary,sz),dtype=torch.cdouble)\n",
    "            elif pauli == 4:\n",
    "                unitary = torch.tensor(np.kron(unitary,id),dtype=torch.cdouble)\n",
    "        SU.append(unitary)\n",
    "\n",
    "    #These are the coefficients we are optimizing\n",
    "    R = torch.rand([M,4*N], dtype=torch.double) *2*np.pi # Random initialization (between 0 and 2pi)\n",
    "    R.requires_grad = True # set flag so we can backpropagate\n",
    "\n",
    "    #Optimizer settings(can be changed & opttimized)\n",
    "    lr=0.3#learning rate\n",
    "\n",
    "    opt = 'SGD'  # Choose optimizer - ADAM, SGD (typical). ADAMW, ADAMax, Adadelta,  \n",
    "                        # Adagrad, Rprop, RMSprop, ASGD, also valid options.     \n",
    "    sched = 'Plateau'  # Choose learning rate scheduler - Plateau, Exponential (typical), Step\n",
    "    \n",
    "    if opt=='ADAM': optimizer = torch.optim.Adam([R], lr = lr, weight_decay=1e-6)\n",
    "    elif opt=='ADAMW': optimizer = torch.optim.AdamW([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='ADAMax': optimizer = torch.optim.Adamax([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='RMSprop': optimizer = torch.optim.RMSprop([R], lr = lr, momentum=0.2)\n",
    "    elif opt=='Rprop': optimizer = torch.optim.Rprop([R], lr = lr)\n",
    "    elif opt=='Adadelta': optimizer = torch.optim.Adadelta([R], lr = lr) \n",
    "    elif opt=='Adagrad': optimizer = torch.optim.Adagrad([R], lr = lr)\n",
    "    elif opt=='SGD': optimizer = torch.optim.SGD([R], lr = lr, momentum=0.99, nesterov=True)\n",
    "    elif opt=='ASGD': optimizer = torch.optim.ASGD([R], lr = lr)\n",
    "    else: optimizer=None; opt='None'\n",
    "        \n",
    "    if sched=='Step': scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=N_iter/10, gamma=0.9)\n",
    "    elif sched=='Exponential': scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    elif sched=='Plateau': scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=0.03, factor=0.3 , patience= 20 ); loss_in=True; \n",
    "    else: scheduler=None; sched='None'\n",
    "\n",
    "    prev_infidelity = -1\n",
    "    change_count = 0\n",
    "    for n in range(0,N_iter):\n",
    "        #Creating Drive Hamilontian\n",
    "        U_Exp = 1\n",
    "        for i in range(0,N):\n",
    "            U_Exp = torch.tensor(np.kron(U_Exp,id),dtype=dt)#initializing unitary\n",
    "        for m in range(0,M):#Product of pulses\n",
    "            pulse_coef = R[m]\n",
    "            H1 = sum_pauli(pulse_coef[:N],sx) + sum_pauli(pulse_coef[N:2*N],sy) + sum_pauli(pulse_coef[2*N:3*N],sxx) + sum_pauli(pulse_coef[3*N:4*N],syy) \n",
    "            U_Exp = torch.matmul(torch.matrix_exp(-1j*(H0+H1)*t/M),U_Exp)\n",
    "\n",
    "        #Fidelity calulcation given by Nielsen Paper\n",
    "        fidelity = 0\n",
    "        d = 2**N\n",
    "        \n",
    "        for U in SU:\n",
    "            eps_U = torch.matmul(torch.matmul(U_Exp,U),(U_Exp.conj().T))\n",
    "            target_U = torch.matmul(torch.matmul(input_gate,(U.conj().T)),(input_gate.conj().T))\n",
    "            tr = torch.trace(torch.matmul(target_U,eps_U))\n",
    "            fidelity = fidelity + tr\n",
    "        fidelity = abs(fidelity + d*d)/(d*d*(d+1))    \n",
    "        infidelity = 1 - fidelity\n",
    "        infidelity_list[n] = infidelity.detach()\n",
    "        infidelity.backward()\n",
    "\n",
    "        #Printing statement\n",
    "        #if (n+1)%100==0: \n",
    "        #    print('Itertation ', str(n+1), ' out of ', str(N_iter), 'complete. Avg Infidelity: ', str(infidelity.item()))\n",
    "\n",
    "        #optimizer \n",
    "        if optimizer is not None and scheduler is None:  # Update R\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        elif optimizer is not None and scheduler is not None:\n",
    "            optimizer.step()\n",
    "            if loss_in: \n",
    "                scheduler.step(infidelity)\n",
    "            else: \n",
    "                scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            R.data.sub_(lr*R.grad.data) # using data avoids overwriting tensor object\n",
    "            R.grad.data.zero_()           # and it's respective grad info\n",
    "        \n",
    "        #Stopping Condition for a lack of change <- do pointer that there is no change for 100 iterations \n",
    "        curr_infidelity = infidelity_list[n]\n",
    "        if prev_infidelity == curr_infidelity:\n",
    "            change_count += 1\n",
    "        if change_count == 100:\n",
    "            #print(\"Breaking due to lack of change\")\n",
    "            #print(\"Infidelity is: \" + str(curr_infidelity))\n",
    "            break\n",
    "        prev_infidelity = curr_infidelity\n",
    "        if 1 - infidelity_list[n] >= 99.99: #Stopping condition for high fidelity iterations\n",
    "            #print(\"Too accurate\" + str(infidelity_list[n]))\n",
    "            break\n",
    "    #print('The infidelity of the generated gate is: ' + str(infidelity_list.min().item()))\n",
    "    #return R\n",
    "    tmin = np.pi/4\n",
    "\n",
    "    pulse_file_time = pulse_file + \"_time\" + str(t/tmin)+\"_\"\n",
    "    np.savetxt(os.path.join(os.getcwd(),\"Pulse_Sequences/\"+pulse_file+\"/\" +pulse_file_time+\".csv\"),R.detach().numpy(),delimiter=\",\") \n",
    "    \n",
    "    return infidelity_list.min().item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qutrit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borabasyildiz/opt/anaconda3/envs/py7/lib/python3.7/site-packages/ipykernel_launcher.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itertation  100  out of  1000 complete. Avg Infidelity:  0.25893763919989554\n",
      "Itertation  200  out of  1000 complete. Avg Infidelity:  0.09909260489846816\n",
      "Itertation  300  out of  1000 complete. Avg Infidelity:  0.04764358870525842\n",
      "Itertation  400  out of  1000 complete. Avg Infidelity:  0.02804347647258254\n",
      "Itertation  500  out of  1000 complete. Avg Infidelity:  0.018644250819475183\n",
      "Itertation  600  out of  1000 complete. Avg Infidelity:  0.011814169072406289\n",
      "Itertation  700  out of  1000 complete. Avg Infidelity:  0.008412022729390456\n",
      "Itertation  800  out of  1000 complete. Avg Infidelity:  0.005364626921315674\n",
      "Itertation  900  out of  1000 complete. Avg Infidelity:  0.0038056108349426854\n",
      "Itertation  1000  out of  1000 complete. Avg Infidelity:  0.003315811201591634\n"
     ]
    }
   ],
   "source": [
    "CNOT_qutrit = torch.tensor([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,1,0,0,0],\n",
    "[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,1]],dtype=torch.cdouble)\n",
    "Identity = torch.tensor([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[0,0,0,0,0,1,0,0,0],\n",
    "[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,1]],dtype=torch.cdouble)\n",
    "J = torch.tensor([[1,1],[1,1]])\n",
    "#pulse_frequencies = fidelity_Qutrit(J,[1,1],24,CNOT_qutrit,np.pi/4,100000)\n",
    "Pulses = fidelity_subQutrit(J,[1,1],32,CNOT_qutrit,np.pi/4,1000,\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borabasyildiz/opt/anaconda3/envs/py7/lib/python3.7/site-packages/ipykernel_launcher.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Qutrit Subsystem Graph Generation \n",
    "\n",
    "#Gate and ferromagnetic variables\n",
    "CNOT_qutrit = torch.tensor([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,1,0,0,0],\n",
    "[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,1]],dtype=torch.cdouble)\n",
    "J = torch.tensor([[1,1],[1,1]])\n",
    "\n",
    "#Iteration variables \n",
    "Fidelities = []\n",
    "Times = []\n",
    "points = np.linspace(0,0.2*np.pi/4,20)\n",
    "points = np.append(points, np.linspace(0.3*np.pi/4,np.pi/4,10))\n",
    "iteration_count = 100\n",
    "\n",
    "#File Creation \n",
    "Pulse_file = \"CNOT_Qutrit_Experimental_couplingOn\"\n",
    "try:\n",
    "    os.makedirs(\"Pulse_Sequences/\"+Pulse_file)\n",
    "except:\n",
    "    shutil.rmtree(\"Pulse_Sequences/\"+Pulse_file)\n",
    "    os.makedirs(\"Pulse_Sequences/\"+Pulse_file)\n",
    "\n",
    "#Generating Points\n",
    "for t in points:\n",
    "    Times.append(t/(np.pi/4))\n",
    "    Fidelities.append(1 - fidelity_subQutrit(J,[1,1],8,CNOT_qutrit,t,iteration_count,Pulse_file))\n",
    "\n",
    "#Saving Fidelities\n",
    "np.savetxt(os.path.join(os.getcwd(),\"Data\",Pulse_file+\".csv\"),Fidelities,delimiter=\",\")\n",
    "\n",
    "#plotting \n",
    "plt.plot(Times,Fidelities,'o-')\n",
    "plt.xlabel(\"T/Tmin\")\n",
    "plt.ylabel(\"Fidelity\")\n",
    "plt.title(\"CNOT Fidelity for Qutrit System with infinite drive\")\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle='dotted', linewidth='0.5')\n",
    "plt.minorticks_on()\n",
    "plt.savefig(os.path.join(os.getcwd(),\"Figures\",Pulse_file+\".pdf\"), format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efa8cc2a4d6f65357a972a944fbd3e02e547e4ca88e36cc716fc5e5cc822571e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
