{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_ml(J,B,M,target_gate,t,N_iter):\n",
    "    #!/usr/bin/env python3\n",
    "    # -*- coding: utf-8 -*-\n",
    "    \"\"\"\n",
    "    Created on Mon Aug 16 4:33 2021\n",
    "\n",
    "    @author: Bora & Alex\n",
    "    \"\"\"\n",
    "    #imports\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from itertools import permutations\n",
    "    from itertools import product\n",
    "\n",
    "    #Pauli Matricies \n",
    "    sx = np.array([[0, 1], [1, 0]])\n",
    "    sy = np.array([[0,-1j],[1j,0]])\n",
    "    sz = np.array([[1, 0], [0, -1]])\n",
    "    id = np.array([[1,0],[0,1]])\n",
    "    \n",
    "    #Function definitions \n",
    "    def zero_mat(N):#Generates matrix of zeros\n",
    "        zero_gate = np.array([[0,0],[0,0]])\n",
    "        init = np.array([[0,0],[0,0]])\n",
    "        if N < 2:\n",
    "            return 1\n",
    "        for i in range(0,N - 1):\n",
    "            zero_gate = torch.tensor(np.kron(zero_gate,init))\n",
    "        return zero_gate\n",
    "    def sum_pauli(coef, gate):#Sums Pauli gates with coefficients \n",
    "        N = len(coef)#number of qubits\n",
    "        total_pauli = zero_mat(N)\n",
    "        #Summing all Z gates\n",
    "        for i in range(0,N):\n",
    "            pauli_temp = 1\n",
    "            for j in range(0,i):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            pauli_temp = torch.tensor(np.kron(pauli_temp,gate))\n",
    "            for j in range(i+1,N):\n",
    "                pauli_temp = torch.tensor(np.kron(pauli_temp,id))\n",
    "            total_pauli = total_pauli + coef[i]*pauli_temp\n",
    "        return total_pauli\n",
    "\n",
    "    #variable initializations\n",
    "    N = len(B)\n",
    "    torch.manual_seed(9)\n",
    "    dt = torch.cdouble # datatype and precision\n",
    "    infidelity_list=torch.zeros([N_iter,1])\n",
    "\n",
    "    #J coefficients gathering (only if J is in N x N matrix, otherwise set J_coef=J)\n",
    "    J_coef = []\n",
    "    for i in range(0,len(J) - 1):\n",
    "        for j in range(0,len(J) - i - 1):\n",
    "            J_coef.append(J[i,j].item())\n",
    "\n",
    "    #H0 generation\n",
    "    permuts = [1,1]\n",
    "    for i in range(2,N):\n",
    "        permuts.append(0)\n",
    "    permuts = list(set(permutations(permuts,N)))\n",
    "    permuts.sort()\n",
    "    permuts.reverse()#All permutations of ZZ coupling stored as bit arrays\n",
    "    H0 = zero_mat(N)\n",
    "    for i,u in enumerate(permuts):#summing ZZ permutations and J constants\n",
    "        ZZ_temp = 1\n",
    "        for p in u:\n",
    "            if p==1:\n",
    "                ZZ_temp = torch.tensor(np.kron(ZZ_temp,sz))\n",
    "            else:\n",
    "                ZZ_temp = torch.tensor(np.kron(ZZ_temp,id))\n",
    "        H0 = H0 + J_coef[i]*ZZ_temp\n",
    "\n",
    "    H0 = H0 + sum_pauli(B,sz)\n",
    "\n",
    "    #Unitary group generation\n",
    "    SU = []\n",
    "    pauli_int = [1, 2, 3, 4]#eq to [sx,sy,sz,id]\n",
    "    perms = list(product(pauli_int,repeat=N))#all permutations of paulis\n",
    "    for p in perms:#mapping integers to pauli \n",
    "        unitary = 1\n",
    "        for pauli in p:\n",
    "            if pauli == 1:\n",
    "                unitary = torch.tensor(np.kron(unitary,sx),dtype=torch.cdouble)\n",
    "            elif pauli == 2:\n",
    "                unitary = torch.tensor(np.kron(unitary,sy),dtype=torch.cdouble)\n",
    "            elif pauli == 3:\n",
    "                unitary = torch.tensor(np.kron(unitary,sz),dtype=torch.cdouble)\n",
    "            elif pauli == 4:\n",
    "                unitary = torch.tensor(np.kron(unitary,id),dtype=torch.cdouble)\n",
    "        SU.append(unitary)\n",
    "\n",
    "    #These are the coefficients we are optimizing\n",
    "    R = torch.rand([M,2*N], dtype=torch.double) *2*np.pi # Random initialization (between 0 and 2pi)\n",
    "    R.requires_grad = True # set flag so we can backpropagate\n",
    "\n",
    "    #Optimizer settings(can be changed & opttimized)\n",
    "    lr=0.3#learning rate\n",
    "\n",
    "    opt = 'SGD'  # Choose optimizer - ADAM, SGD (typical). ADAMW, ADAMax, Adadelta,  \n",
    "                        # Adagrad, Rprop, RMSprop, ASGD, also valid options.     \n",
    "    sched = 'Plateau'  # Choose learning rate scheduler - Plateau, Exponential (typical), Step\n",
    "    \n",
    "    if opt=='ADAM': optimizer = torch.optim.Adam([R], lr = lr, weight_decay=1e-6)\n",
    "    elif opt=='ADAMW': optimizer = torch.optim.AdamW([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='ADAMax': optimizer = torch.optim.Adamax([R], lr = lr, weight_decay=0.01)\n",
    "    elif opt=='RMSprop': optimizer = torch.optim.RMSprop([R], lr = lr, momentum=0.2)\n",
    "    elif opt=='Rprop': optimizer = torch.optim.Rprop([R], lr = lr)\n",
    "    elif opt=='Adadelta': optimizer = torch.optim.Adadelta([R], lr = lr) \n",
    "    elif opt=='Adagrad': optimizer = torch.optim.Adagrad([R], lr = lr)\n",
    "    elif opt=='SGD': optimizer = torch.optim.SGD([R], lr = lr, momentum=0.99, nesterov=True)\n",
    "    elif opt=='ASGD': optimizer = torch.optim.ASGD([R], lr = lr)\n",
    "    else: optimizer=None; opt='None'\n",
    "        \n",
    "    if sched=='Step': scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=N_iter/10, gamma=0.9)\n",
    "    elif sched=='Exponential': scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    elif sched=='Plateau': scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=0.03, factor=0.3 , patience= 20 ); loss_in=True; \n",
    "    else: scheduler=None; sched='None'\n",
    "\n",
    "    for n in range(0,N_iter):\n",
    "        #Creating Hamilontian\n",
    "        U_Exp = 1\n",
    "        for i in range(0,N):\n",
    "            U_Exp = torch.tensor(np.kron(U_Exp,id),dtype=dt)#initializing unitary\n",
    "        for m in range(0,M):#Product of pulses\n",
    "            pulse_coef = R[m]\n",
    "            H1 = sum_pauli(pulse_coef[:N],sx) + sum_pauli(pulse_coef[N:],sy)\n",
    "            U_Exp = torch.matmul(torch.matrix_exp(-1j*(H0+H1)*t/M),U_Exp)\n",
    "\n",
    "        #Fidelity calulcation given by Nielsen Paper\n",
    "        fidelity = 0\n",
    "        d = 2**N\n",
    "        for i in range(0,len(SU)):\n",
    "            eps_U = torch.matmul(torch.matmul(U_Exp,SU[i]),(U_Exp.conj().T))\n",
    "            target_U = torch.matmul(torch.matmul(target_gate,(SU[i].conj().T)),(target_gate.conj().T))\n",
    "            tr = torch.trace(torch.matmul(target_U,eps_U))\n",
    "            fidelity = fidelity + tr\n",
    "        fidelity = abs(fidelity + d*d)/(d*d*(d+1))    \n",
    "        infidelity = 1 - fidelity\n",
    "        infidelity_list[n] = infidelity.detach()\n",
    "        infidelity.backward()\n",
    "\n",
    "        #Printing statement\n",
    "        if (n+1)%20==0: \n",
    "            print('Itertation ', str(n+1), ' out of ', str(N_iter), 'complete. Avg Infidelity: ', str(infidelity.item()))\n",
    "\n",
    "        #optimizer \n",
    "        if optimizer is not None and scheduler is None:  # Update R\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        elif optimizer is not None and scheduler is not None:\n",
    "            optimizer.step()\n",
    "            if loss_in: \n",
    "                scheduler.step(infidelity)\n",
    "            else: \n",
    "                scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            R.data.sub_(lr*R.grad.data) # using data avoids overwriting tensor object\n",
    "            R.grad.data.zero_()           # and it's respective grad info\n",
    "    \n",
    "    print('The infidelity of the generated gate is: ' + str(infidelity_list.min().item()))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing fidelity function\n",
    "#2 qubit gates (works great :) )\n",
    "import torch\n",
    "import numpy as np\n",
    "target_gates =[torch.tensor((1/np.sqrt(2))*np.kron(np.array([[1,-1j],[-1j,1]]),np.eye(2)),dtype=torch.cdouble),\n",
    "                torch.tensor([[1,0,0,0],[0,1,0,0],[0,0,0,1],[0,0,1,0]], dtype=torch.cdouble),\n",
    "                torch.tensor([[1,0,0,0],[0, 0, 1j, 0], [0, 1j,0,0],[0,0,0,1]], dtype=torch.cdouble),\n",
    "                torch.tensor([[1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]], dtype=torch.cdouble),\n",
    "                torch.tensor([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,-1]], dtype=torch.cdouble)]\n",
    "#3 qubit gates (works great as well!!)\n",
    "toffoli = torch.tensor([[1,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0],[0,0,1,0,0,0,0,0],[0,0,0,1,0,0,0,0],[0,0,0,0,1,0,0,0],[0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1],[0,0,0,0,0,0,1,0]],dtype=torch.cdouble)\n",
    "J = torch.tensor([[1,1,1],[1,1,1],[1,1,1]])\n",
    "Coef = fidelity_ml(J,[1,1,1],12,toffoli,np.pi,300)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
